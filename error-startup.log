C:\dev\jdk14\bin\java.exe -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA 2020.3\lib\idea_rt.jar=52697:C:\Program Files\JetBrains\IntelliJ IDEA 2020.3\bin" -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -Dfile.encoding=UTF-8 -classpath F:\dev\kafkastream-statestore-migrated-to-another-instance\target\classes;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-web\2.4.2\spring-boot-starter-web-2.4.2.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter\2.4.2\spring-boot-starter-2.4.2.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot\2.4.2\spring-boot-2.4.2.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.4.2\spring-boot-autoconfigure-2.4.2.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.4.2\spring-boot-starter-logging-2.4.2.jar;C:\Users\survivant\.m2\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;C:\Users\survivant\.m2\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;C:\Users\survivant\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.13.3\log4j-to-slf4j-2.13.3.jar;C:\Users\survivant\.m2\repository\org\apache\logging\log4j\log4j-api\2.13.3\log4j-api-2.13.3.jar;C:\Users\survivant\.m2\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;C:\Users\survivant\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\survivant\.m2\repository\org\yaml\snakeyaml\1.27\snakeyaml-1.27.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-json\2.4.2\spring-boot-starter-json-2.4.2.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.11.4\jackson-databind-2.11.4.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.11.4\jackson-core-2.11.4.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.4\jackson-datatype-jdk8-2.11.4.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.4\jackson-datatype-jsr310-2.11.4.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.4\jackson-module-parameter-names-2.11.4.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.4.2\spring-boot-starter-tomcat-2.4.2.jar;C:\Users\survivant\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.41\tomcat-embed-core-9.0.41.jar;C:\Users\survivant\.m2\repository\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;C:\Users\survivant\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.41\tomcat-embed-websocket-9.0.41.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-web\5.3.3\spring-web-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-beans\5.3.3\spring-beans-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-webmvc\5.3.3\spring-webmvc-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-aop\5.3.3\spring-aop-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-expression\5.3.3\spring-expression-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\2.4.2\spring-boot-starter-webflux-2.4.2.jar;C:\Users\survivant\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\2.4.2\spring-boot-starter-reactor-netty-2.4.2.jar;C:\Users\survivant\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.0.3\reactor-netty-http-1.0.3.jar;C:\Users\survivant\.m2\repository\io\netty\netty-codec-http\4.1.58.Final\netty-codec-http-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-common\4.1.58.Final\netty-common-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-buffer\4.1.58.Final\netty-buffer-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-transport\4.1.58.Final\netty-transport-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-codec\4.1.58.Final\netty-codec-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-codec-http2\4.1.58.Final\netty-codec-http2-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-resolver-dns\4.1.58.Final\netty-resolver-dns-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-resolver\4.1.58.Final\netty-resolver-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-codec-dns\4.1.58.Final\netty-codec-dns-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.58.Final\netty-resolver-dns-native-macos-4.1.58.Final-osx-x86_64.jar;C:\Users\survivant\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.58.Final\netty-transport-native-unix-common-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-transport-native-epoll\4.1.58.Final\netty-transport-native-epoll-4.1.58.Final-linux-x86_64.jar;C:\Users\survivant\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.0.3\reactor-netty-core-1.0.3.jar;C:\Users\survivant\.m2\repository\io\netty\netty-handler-proxy\4.1.58.Final\netty-handler-proxy-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\io\netty\netty-codec-socks\4.1.58.Final\netty-codec-socks-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-webflux\5.3.3\spring-webflux-5.3.3.jar;C:\Users\survivant\.m2\repository\org\apache\kafka\kafka-streams\2.6.0\kafka-streams-2.6.0.jar;C:\Users\survivant\.m2\repository\org\apache\kafka\kafka-clients\2.6.0\kafka-clients-2.6.0.jar;C:\Users\survivant\.m2\repository\com\github\luben\zstd-jni\1.4.4-7\zstd-jni-1.4.4-7.jar;C:\Users\survivant\.m2\repository\org\lz4\lz4-java\1.7.1\lz4-java-1.7.1.jar;C:\Users\survivant\.m2\repository\org\xerial\snappy\snappy-java\1.1.7.3\snappy-java-1.1.7.3.jar;C:\Users\survivant\.m2\repository\org\apache\kafka\connect-json\2.6.0\connect-json-2.6.0.jar;C:\Users\survivant\.m2\repository\org\apache\kafka\connect-api\2.6.0\connect-api-2.6.0.jar;C:\Users\survivant\.m2\repository\org\slf4j\slf4j-api\1.7.30\slf4j-api-1.7.30.jar;C:\Users\survivant\.m2\repository\org\rocksdb\rocksdbjni\5.18.4\rocksdbjni-5.18.4.jar;C:\Users\survivant\.m2\repository\org\springframework\kafka\spring-kafka\2.6.5\spring-kafka-2.6.5.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-context\5.3.3\spring-context-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-messaging\5.3.3\spring-messaging-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-tx\5.3.3\spring-tx-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\retry\spring-retry\1.3.1\spring-retry-1.3.1.jar;C:\Users\survivant\.m2\repository\javax\annotation\javax.annotation-api\1.3.2\javax.annotation-api-1.3.2.jar;C:\Users\survivant\.m2\repository\org\projectlombok\lombok\1.18.16\lombok-1.18.16.jar;C:\Users\survivant\.m2\repository\net\bytebuddy\byte-buddy\1.10.19\byte-buddy-1.10.19.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-core\5.3.3\spring-core-5.3.3.jar;C:\Users\survivant\.m2\repository\org\springframework\spring-jcl\5.3.3\spring-jcl-5.3.3.jar;C:\Users\survivant\.m2\repository\io\projectreactor\reactor-core\3.4.2\reactor-core-3.4.2.jar;C:\Users\survivant\.m2\repository\org\reactivestreams\reactive-streams\1.0.3\reactive-streams-1.0.3.jar;C:\Users\survivant\.m2\repository\io\netty\netty-handler\4.1.58.Final\netty-handler-4.1.58.Final.jar;C:\Users\survivant\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.11.4\jackson-annotations-2.11.4.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-swagger2\2.9.2\springfox-swagger2-2.9.2.jar;C:\Users\survivant\.m2\repository\io\swagger\swagger-annotations\1.5.20\swagger-annotations-1.5.20.jar;C:\Users\survivant\.m2\repository\io\swagger\swagger-models\1.5.20\swagger-models-1.5.20.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-spi\2.9.2\springfox-spi-2.9.2.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-core\2.9.2\springfox-core-2.9.2.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-schema\2.9.2\springfox-schema-2.9.2.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-swagger-common\2.9.2\springfox-swagger-common-2.9.2.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-spring-web\2.9.2\springfox-spring-web-2.9.2.jar;C:\Users\survivant\.m2\repository\com\google\guava\guava\20.0\guava-20.0.jar;C:\Users\survivant\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\survivant\.m2\repository\org\springframework\plugin\spring-plugin-core\1.2.0.RELEASE\spring-plugin-core-1.2.0.RELEASE.jar;C:\Users\survivant\.m2\repository\org\springframework\plugin\spring-plugin-metadata\1.2.0.RELEASE\spring-plugin-metadata-1.2.0.RELEASE.jar;C:\Users\survivant\.m2\repository\org\mapstruct\mapstruct\1.2.0.Final\mapstruct-1.2.0.Final.jar;C:\Users\survivant\.m2\repository\io\springfox\springfox-swagger-ui\2.9.2\springfox-swagger-ui-2.9.2.jar com.example.kafkaeventalarm.KafkaEventAlarmApplication
OpenJDK 64-Bit Server VM warning: Options -Xverify:none and -noverify were deprecated in JDK 13 and will likely be removed in a future release.

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.4.2)

2021-05-17 18:05:18.652  INFO 18012 --- [           main] c.e.k.KafkaEventAlarmApplication         : Starting KafkaEventAlarmApplication using Java 14.0.1 on LenovoP70 with PID 18012 (F:\dev\kafkastream-statestore-migrated-to-another-instance\target\classes started by survivant in F:\dev\kafkastream-statestore-migrated-to-another-instance)
2021-05-17 18:05:18.652  INFO 18012 --- [           main] c.e.k.KafkaEventAlarmApplication         : No active profile set, falling back to default profiles: default
2021-05-17 18:05:20.459  INFO 18012 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8282 (http)
2021-05-17 18:05:20.474  INFO 18012 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2021-05-17 18:05:20.474  INFO 18012 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.41]
2021-05-17 18:05:20.555  INFO 18012 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2021-05-17 18:05:20.555  INFO 18012 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1835 ms
2021-05-17 18:05:20.707  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = OrderStreamProcessor2
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = OrderStreamProcessor2
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:20.722  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] Kafka Streams version: 2.6.0
2021-05-17 18:05:20.722  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:20.738  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:20.785  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.785  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.785  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120785
2021-05-17 18:05:20.801  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:20.801  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.829  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.829  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.829  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120829
2021-05-17 18:05:20.831  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating thread producer client
2021-05-17 18:05:20.831  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:20.855  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.855  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.855  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120855
2021-05-17 18:05:20.865  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating consumer client
2021-05-17 18:05:20.867  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = OrderStreamProcessor2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.875  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:20.881  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:20.881  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:20.881  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.881  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.881  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120881
2021-05-17 18:05:20.881  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from CREATED to REBALANCING
2021-05-17 18:05:20.881  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Starting
2021-05-17 18:05:20.881  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:20.881  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Subscribed to topic(s): OrderStreamProcessor2-orders-status-count-repartition, orders
2021-05-17 18:05:20.905  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = OrderStreamProcessorWindow
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = OrderStreamProcessorWindow
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:20.905  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] Kafka Streams version: 2.6.0
2021-05-17 18:05:20.905  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120907
2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:20.907  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.925  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.925  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.925  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120925
2021-05-17 18:05:20.926  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating thread producer client
2021-05-17 18:05:20.927  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:20.931  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.931  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.931  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120931
2021-05-17 18:05:20.931  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating consumer client
2021-05-17 18:05:20.933  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = OrderStreamProcessorWindow
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.939  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:20.941  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:20.941  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:20.941  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.941  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.941  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120941
2021-05-17 18:05:20.944  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from CREATED to REBALANCING
2021-05-17 18:05:20.945  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Starting
2021-05-17 18:05:20.945  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:20.945  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Subscribed to topic(s): OrderStreamProcessorWindow-countsWindow-repartition, orders-window
2021-05-17 18:05:20.950  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = NumberStreamProcessor2
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = NumberStreamProcessor2
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:20.950  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] Kafka Streams version: 2.6.0
2021-05-17 18:05:20.955  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120955
2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:20.955  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.969  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.969  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.969  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120969
2021-05-17 18:05:20.969  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating thread producer client
2021-05-17 18:05:20.970  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:20.975  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.976  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.976  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120974
2021-05-17 18:05:20.977  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating consumer client
2021-05-17 18:05:20.978  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = NumberStreamProcessor2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:20.985  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:20.987  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:20.987  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:20.988  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:20.988  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:20.988  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289120987
2021-05-17 18:05:20.996  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from CREATED to REBALANCING
2021-05-17 18:05:20.996  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Starting
2021-05-17 18:05:20.996  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:20.996  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Subscribed to topic(s): NumberStreamProcessor2-counts-repartition, numbers
2021-05-17 18:05:21.109  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 2 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.110  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.111  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 2 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.112  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.112  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=OrderStreamProcessor2-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.116  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 2 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.116  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.118  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=NumberStreamProcessor2-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.118  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=OrderStreamProcessorWindow-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:21.254  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 5 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.269  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 5 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.269  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 4 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.364  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 7 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.401  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 7 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.405  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 6 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.496  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 10 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.523  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 10 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.526  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 9 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.609  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 12 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.627  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = default
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id =
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:21.638  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 12 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.638  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 11 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.656  INFO 18012 --- [           main] pertySourcedRequestMappingHandlerMapping : Mapped URL path [/v2/api-docs] onto method [springfox.documentation.swagger2.web.Swagger2Controller#getDocumentation(String, HttpServletRequest)]
2021-05-17 18:05:21.714  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 15 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.760  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 14 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.761  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 15 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.832  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 18 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.855  INFO 18012 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2021-05-17 18:05:21.871  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 16 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.871  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 18 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.938  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 21 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.993  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 21 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:21.993  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 18 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.050  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 23 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.099  INFO 18012 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2021-05-17 18:05:22.101  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 21 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.108  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 23 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.153  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 25 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.164  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id =
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:22.168  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.169  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.169  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122168
2021-05-17 18:05:22.218  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.221  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.234  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 24 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.243  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.244  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.268  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 27 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.271  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 27 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.271  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.273  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.314  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.352  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 29 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION, numbers=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.383  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 30 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION, orders=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.384  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 32 : {orders-window=UNKNOWN_TOPIC_OR_PARTITION, OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.392 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Source topic orders-window is missing/unknown during rebalance, please make sure all source topics have been pre-created before starting the Streams application. Returning error INCOMPLETE_SOURCE_TOPIC_METADATA
2021-05-17 18:05:22.392 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Source topic orders is missing/unknown during rebalance, please make sure all source topics have been pre-created before starting the Streams application. Returning error INCOMPLETE_SOURCE_TOPIC_METADATA
2021-05-17 18:05:22.396  WARN 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] The following subscribed topics are not assigned to any members: [orders-window, OrderStreamProcessorWindow-countsWindow-repartition]
2021-05-17 18:05:22.396  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Finished assignment for group at generation 1: {OrderStreamProcessorWindow-StreamThread-1-consumer-72c82e06-39ff-4bc2-9bd2-7e5358ddcf8a=Assignment(partitions=[], userDataSize=40)}
2021-05-17 18:05:22.396  WARN 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] The following subscribed topics are not assigned to any members: [OrderStreamProcessor2-orders-status-count-repartition, orders]
2021-05-17 18:05:22.397  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Finished assignment for group at generation 1: {OrderStreamProcessor2-StreamThread-1-consumer-9e9ed386-51a3-4293-804e-b69fef9de260=Assignment(partitions=[], userDataSize=40)}
2021-05-17 18:05:22.439  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Successfully joined group with generation 1
2021-05-17 18:05:22.439  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Successfully joined group with generation 1
2021-05-17 18:05:22.440  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:22.440  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:22.440  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:22.440  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:22.441  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:22.441 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Received error code 1 - shutdown
2021-05-17 18:05:22.442  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Informed to shut down
2021-05-17 18:05:22.442  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from STARTING to PENDING_SHUTDOWN
2021-05-17 18:05:22.442  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Adding newly assigned partitions:
2021-05-17 18:05:22.442 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Received error code 1 - shutdown
2021-05-17 18:05:22.443  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Informed to shut down
2021-05-17 18:05:22.443  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from STARTING to PENDING_SHUTDOWN
2021-05-17 18:05:22.471  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Error while fetching metadata with correlation id 30 : {NumberStreamProcessor2-counts-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.495  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 34 : {OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.496  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 32 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.500  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.500  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.608  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 34 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.608  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Error while fetching metadata with correlation id 36 : {OrderStreamProcessorWindow-countsWindow-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.616  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = NumberStreamProcessor2
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = NumberStreamProcessor2
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:22.617  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] Kafka Streams version: 2.6.0
2021-05-17 18:05:22.618  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:22.619  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:22.623  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.623  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.623  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122623
2021-05-17 18:05:22.632  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=NumberStreamProcessor2-admin
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:549) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:73) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getAdmin(DefaultKafkaClientSupplier.java:41) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:767) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.634  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:22.635  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.640  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.641  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.641  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122640
2021-05-17 18:05:22.641  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=NumberStreamProcessor2-StreamThread-1-restore-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getRestoreConsumer(DefaultKafkaClientSupplier.java:56) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:304) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.642  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating thread producer client
2021-05-17 18:05:22.643  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:22.652  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.652  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.652  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122652
2021-05-17 18:05:22.655  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=NumberStreamProcessor2-StreamThread-1-producer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:435) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:290) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getProducer(DefaultKafkaClientSupplier.java:46) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamsProducer.<init>(StreamsProducer.java:128) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.ActiveTaskCreator.<init>(ActiveTaskCreator.java:101) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:317) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.655  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Creating consumer client
2021-05-17 18:05:22.657  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = NumberStreamProcessor2-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = NumberStreamProcessor2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.661  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:22.663  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:22.663  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:22.663  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.663  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.663  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122663
2021-05-17 18:05:22.664  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=NumberStreamProcessor2-StreamThread-1-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getConsumer(DefaultKafkaClientSupplier.java:51) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:369) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.666  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from CREATED to REBALANCING
2021-05-17 18:05:22.666  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Starting
2021-05-17 18:05:22.666  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:22.666  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = OrderStreamProcessor2
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = OrderStreamProcessor2
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:22.667  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Subscribed to topic(s): NumberStreamProcessor2-counts-repartition, numbers
2021-05-17 18:05:22.667  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] Kafka Streams version: 2.6.0
2021-05-17 18:05:22.667  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:22.668  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:22.671  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.671  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.671  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122671
2021-05-17 18:05:22.671  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=OrderStreamProcessor2-admin
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:549) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:73) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getAdmin(DefaultKafkaClientSupplier.java:41) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:767) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.671  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:22.672  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.678  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.678  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.678  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122678
2021-05-17 18:05:22.679  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=OrderStreamProcessor2-StreamThread-1-restore-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getRestoreConsumer(DefaultKafkaClientSupplier.java:56) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:304) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.681  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating thread producer client
2021-05-17 18:05:22.682  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:22.688  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.688  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.688  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122688
2021-05-17 18:05:22.689  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=OrderStreamProcessor2-StreamThread-1-producer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:435) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:290) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getProducer(DefaultKafkaClientSupplier.java:46) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamsProducer.<init>(StreamsProducer.java:128) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.ActiveTaskCreator.<init>(ActiveTaskCreator.java:101) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:317) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.689  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Creating consumer client
2021-05-17 18:05:22.690  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessor2-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = OrderStreamProcessor2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.691  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2021-05-17 18:05:22.692  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2].
2021-05-17 18:05:22.694  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:22.705  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:22.705  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Finished assignment for group at generation 1: {NumberStreamProcessor2-StreamThread-1-consumer-438924a5-16f8-4be1-bbbc-ab7e65f4f73a=Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0, numbers-0], userDataSize=56)}
2021-05-17 18:05:22.706  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:22.706  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:22.707  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.707  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.707  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122707
2021-05-17 18:05:22.707  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=OrderStreamProcessor2-StreamThread-1-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getConsumer(DefaultKafkaClientSupplier.java:51) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:369) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.709  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from CREATED to REBALANCING
2021-05-17 18:05:22.710  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Starting
2021-05-17 18:05:22.711  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:22.712  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Subscribed to topic(s): OrderStreamProcessor2-orders-status-count-repartition, orders
2021-05-17 18:05:22.713  INFO 18012 --- [           main] org.apache.kafka.streams.StreamsConfig   : StreamsConfig values:
	acceptable.recovery.lag = 10000
	application.id = OrderStreamProcessorWindow
	application.server =
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 0
	client.id = OrderStreamProcessorWindow
	commit.interval.ms = 5000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

2021-05-17 18:05:22.715  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] Kafka Streams version: 2.6.0
2021-05-17 18:05:22.715  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] Kafka Streams commit ID: 62abe01bee039651
2021-05-17 18:05:22.716  INFO 18012 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values:
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2021-05-17 18:05:22.719  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.720  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.721  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122719
2021-05-17 18:05:22.723  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=OrderStreamProcessorWindow-admin
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:549) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:73) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getAdmin(DefaultKafkaClientSupplier.java:41) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:767) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.724  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.725  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating restore consumer client
2021-05-17 18:05:22.725  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 1
2021-05-17 18:05:22.725  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       [NumberStreamProcessor2-counts-repartition-0, numbers-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [NumberStreamProcessor2-counts-repartition-0, numbers-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:22.725  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0, numbers-0], userDataSize=56)
2021-05-17 18:05:22.727  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:22.729  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-restore-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.729  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0, 1_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:22.731  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.732  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.735  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.735  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.735  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122735
2021-05-17 18:05:22.736  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=OrderStreamProcessorWindow-StreamThread-1-restore-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getRestoreConsumer(DefaultKafkaClientSupplier.java:56) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:304) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.736  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating thread producer client
2021-05-17 18:05:22.736  INFO 18012 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 10000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2021-05-17 18:05:22.741  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=OrderStreamProcessor2-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.741  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.742  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.742  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122741
2021-05-17 18:05:22.742  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=OrderStreamProcessorWindow-StreamThread-1-producer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:435) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:290) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getProducer(DefaultKafkaClientSupplier.java:46) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamsProducer.<init>(StreamsProducer.java:128) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.ActiveTaskCreator.<init>(ActiveTaskCreator.java:101) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:317) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.743  INFO 18012 --- [           main] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Creating consumer client
2021-05-17 18:05:22.743  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderStreamProcessorWindow-StreamThread-1-consumer
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = OrderStreamProcessorWindow
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2021-05-17 18:05:22.745  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=NumberStreamProcessor2-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.751  INFO 18012 --- [           main] o.a.k.s.p.i.a.AssignorConfiguration      : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Cooperative rebalancing enabled now
2021-05-17 18:05:22.755  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
2021-05-17 18:05:22.756  WARN 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : The configuration 'admin.retries' was supplied but isn't a known config.
2021-05-17 18:05:22.756  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.756  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.758  WARN 18012 --- [-StreamThread-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Error while fetching metadata with correlation id 2 : {OrderStreamProcessor2-orders-status-count-repartition=UNKNOWN_TOPIC_OR_PARTITION}
2021-05-17 18:05:22.758  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.759  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.759  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122756
2021-05-17 18:05:22.760  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.760  WARN 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Error registering AppInfo mbean

javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=OrderStreamProcessorWindow-StreamThread-1-consumer
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890) ~[na:na]
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320) ~[na:na]
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[na:na]
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:814) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:632) ~[kafka-clients-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getConsumer(DefaultKafkaClientSupplier.java:51) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:369) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:772) ~[kafka-streams-2.6.0.jar:na]
	at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:583) ~[kafka-streams-2.6.0.jar:na]
	at org.springframework.kafka.config.StreamsBuilderFactoryBean.start(StreamsBuilderFactoryBean.java:316) ~[spring-kafka-2.6.5.jar:2.6.5]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356) ~[spring-context-5.3.3.jar:5.3.3]
	at java.base/java.lang.Iterable.forEach(Iterable.java:75) ~[na:na]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:940) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:591) ~[spring-context-5.3.3.jar:5.3.3]
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) ~[spring-boot-2.4.2.jar:2.4.2]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) ~[spring-boot-2.4.2.jar:2.4.2]
	at com.example.kafkaeventalarm.KafkaEventAlarmApplication.main(KafkaEventAlarmApplication.java:12) ~[classes/:na]

2021-05-17 18:05:22.762  INFO 18012 --- [           main] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from CREATED to REBALANCING
2021-05-17 18:05:22.767  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Starting
2021-05-17 18:05:22.767  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from CREATED to STARTING
2021-05-17 18:05:22.767  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Subscribed to topic(s): OrderStreamProcessorWindow-countsWindow-repartition, orders-window
2021-05-17 18:05:22.768  INFO 18012 --- [read-1-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=OrderStreamProcessorWindow-StreamThread-1-producer] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.768  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.768  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.782  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = ReturnConsumer-0
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = demo-alarm-event
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2021-05-17 18:05:22.782  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions: NumberStreamProcessor2-counts-repartition-0, numbers-0
2021-05-17 18:05:22.782  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
2021-05-17 18:05:22.782  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.789  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.789  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.792  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.792  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.792  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122792
2021-05-17 18:05:22.793  INFO 18012 --- [           main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Subscribed to topic(s): returns
2021-05-17 18:05:22.794  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.796  INFO 18012 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-17 18:05:22.799  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.800  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.804  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = OrderConsumer-0
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = demo-alarm-event
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2021-05-17 18:05:22.814  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.814  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.815  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.815  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.815  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122815
2021-05-17 18:05:22.815  INFO 18012 --- [           main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Subscribed to topic(s): orders
2021-05-17 18:05:22.815  INFO 18012 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-17 18:05:22.817  INFO 18012 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = NumberConsumer-0
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = demo-alarm-event
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2021-05-17 18:05:22.827  INFO 18012 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.827  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:22.827  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:22.827  INFO 18012 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289122827
2021-05-17 18:05:22.827  INFO 18012 --- [           main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Subscribed to topic(s): numbers
2021-05-17 18:05:22.827  INFO 18012 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2021-05-17 18:05:22.829  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([0_0, 1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([NumberStreamProcessor2-counts-repartition-0, numbers-0]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1], 2b4baf5a-ae10-437c-85f8-5087c470e060=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]} with no followup probing rebalance.
2021-05-17 18:05:22.829  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
2b4baf5a-ae10-437c-85f8-5087c470e060=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]
b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([0_0, 1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([NumberStreamProcessor2-counts-repartition-0, numbers-0]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1].
2021-05-17 18:05:22.829  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Removing task 0_0 from NumberStreamProcessor2-StreamThread-1-consumer-e1fd483a-6582-4395-bdba-fdf1746f8cd3 active assignment until it is safely revoked in followup rebalance
2021-05-17 18:05:22.829  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately due to tasks changing ownership.
2021-05-17 18:05:22.830  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Finished unstable assignment of tasks, a followup rebalance will be scheduled.
2021-05-17 18:05:22.830  WARN 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] The following subscribed topics are not assigned to any members: [numbers]
2021-05-17 18:05:22.830  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Finished assignment for group at generation 2: {NumberStreamProcessor2-StreamThread-1-consumer-438924a5-16f8-4be1-bbbc-ab7e65f4f73a=Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0], userDataSize=48), NumberStreamProcessor2-StreamThread-1-consumer-e1fd483a-6582-4395-bdba-fdf1746f8cd3=Assignment(partitions=[], userDataSize=40)}
2021-05-17 18:05:22.831  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Initialized
2021-05-17 18:05:22.832  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.833  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.837  INFO 18012 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.842  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:22.842  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.842  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:22.843  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:22.843  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:22.843  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:22.843  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:22.843  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
2021-05-17 18:05:22.845  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.854  INFO 18012 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8282 (http) with context path ''
2021-05-17 18:05:22.856  INFO 18012 --- [           main] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2021-05-17 18:05:22.870  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:22.871  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:22.871  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:22.871  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.879  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:22.879  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:22.879  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:22.879  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:22.880  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:22.880  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:22.880  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:22.880  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:22.887  INFO 18012 --- [           main] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2021-05-17 18:05:22.903  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.903  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.904  INFO 18012 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:22.906  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2021-05-17 18:05:22.906  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.906  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.907  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.943  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {3a5f2c4e-4766-4f21-a9ae-445860454bbd=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2021-05-17 18:05:22.944  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Assigned tasks to clients as
3a5f2c4e-4766-4f21-a9ae-445860454bbd=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2].
2021-05-17 18:05:22.944  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:22.944  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Finished assignment for group at generation 2: {OrderStreamProcessorWindow-StreamThread-1-consumer-72c82e06-39ff-4bc2-9bd2-7e5358ddcf8a=Assignment(partitions=[OrderStreamProcessorWindow-countsWindow-repartition-0, orders-window-0], userDataSize=56)}
2021-05-17 18:05:22.959  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {568398b7-02fd-47b0-be07-d9e268b4c239=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2021-05-17 18:05:22.959  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
568398b7-02fd-47b0-be07-d9e268b4c239=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2].
2021-05-17 18:05:22.959  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:22.960  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Finished assignment for group at generation 2: {OrderStreamProcessor2-StreamThread-1-consumer-9e9ed386-51a3-4293-804e-b69fef9de260=Assignment(partitions=[OrderStreamProcessor2-orders-status-count-repartition-0, orders-0], userDataSize=56)}
2021-05-17 18:05:22.961  INFO 18012 --- [           main] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2021-05-17 18:05:22.961  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2021-05-17 18:05:22.961  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:22.977  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:22.977  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:22.977  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:22.977  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.988  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.
2021-05-17 18:05:22.988  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:22.988  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2021-05-17 18:05:22.988  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:22.988  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Finished assignment for group at generation 1: {OrderConsumer-0-a573c40a-b370-4455-a2d7-7396c7098726=Assignment(partitions=[orders-0]), ReturnConsumer-0-b43170e7-6fa1-44fb-8ec0-8b2546101d9b=Assignment(partitions=[returns-0])}
2021-05-17 18:05:23.002  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.003  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2021-05-17 18:05:23.003  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.003  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.003  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Join group failed with org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2021-05-17 18:05:23.003  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] (Re-)joining group
2021-05-17 18:05:23.014  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Finished assignment for group at generation 2: {OrderConsumer-0-a573c40a-b370-4455-a2d7-7396c7098726=Assignment(partitions=[orders-0]), ReturnConsumer-0-b43170e7-6fa1-44fb-8ec0-8b2546101d9b=Assignment(partitions=[returns-0]), NumberConsumer-0-e468a3b6-f432-4a13-9cd6-09c7a371faff=Assignment(partitions=[numbers-0])}
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Successfully joined group with generation 2
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Successfully joined group with generation 2
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Notifying assignor about the new Assignment(partitions=[numbers-0])
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Notifying assignor about the new Assignment(partitions=[returns-0])
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Adding newly assigned partitions: numbers-0
2021-05-17 18:05:23.026  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Adding newly assigned partitions: returns-0
2021-05-17 18:05:23.029  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Successfully joined group with generation 2
2021-05-17 18:05:23.030  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Notifying assignor about the new Assignment(partitions=[orders-0])
2021-05-17 18:05:23.030  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Adding newly assigned partitions: orders-0
2021-05-17 18:05:23.036  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {568398b7-02fd-47b0-be07-d9e268b4c239=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1], 676f7e50-93dc-4be5-ad75-34256c835121=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]} with no followup probing rebalance.
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
568398b7-02fd-47b0-be07-d9e268b4c239=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]
676f7e50-93dc-4be5-ad75-34256c835121=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1].
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {0fa30c47-d32d-481f-957a-43e2c0c7e4a3=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1], 3a5f2c4e-4766-4f21-a9ae-445860454bbd=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]} with no followup probing rebalance.
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Assigned tasks to clients as
3a5f2c4e-4766-4f21-a9ae-445860454bbd=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]
0fa30c47-d32d-481f-957a-43e2c0c7e4a3=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1].
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Finished assignment for group at generation 3: {OrderStreamProcessor2-StreamThread-1-consumer-9e9ed386-51a3-4293-804e-b69fef9de260=Assignment(partitions=[OrderStreamProcessor2-orders-status-count-repartition-0], userDataSize=48), OrderStreamProcessor2-StreamThread-1-consumer-bf6909b2-f484-4542-afdf-7465f8e3477d=Assignment(partitions=[orders-0], userDataSize=48)}
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:23.037  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Finished assignment for group at generation 3: {OrderStreamProcessorWindow-StreamThread-1-consumer-72c82e06-39ff-4bc2-9bd2-7e5358ddcf8a=Assignment(partitions=[orders-window-0], userDataSize=48), OrderStreamProcessorWindow-StreamThread-1-consumer-57d99ddf-fdc1-4331-b5e5-da0e70cf635e=Assignment(partitions=[OrderStreamProcessorWindow-countsWindow-repartition-0], userDataSize=48)}
2021-05-17 18:05:23.053  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition returns-0
2021-05-17 18:05:23.053  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition orders-0
2021-05-17 18:05:23.053  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition numbers-0
2021-05-17 18:05:23.065  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition orders-0
2021-05-17 18:05:23.069  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Successfully joined group with generation 3
2021-05-17 18:05:23.069  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Successfully joined group with generation 3
2021-05-17 18:05:23.069  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition numbers-0
2021-05-17 18:05:23.071  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Updating assignment with
	Assigned partitions:                       [orders-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [orders-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.071  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Notifying assignor about the new Assignment(partitions=[orders-0], userDataSize=48)
2021-05-17 18:05:23.071  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.071  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.073  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Found no committed offset for partition returns-0
2021-05-17 18:05:23.074  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Adding newly assigned partitions: orders-0
2021-05-17 18:05:23.074  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.075  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Updating assignment with
	Assigned partitions:                       [OrderStreamProcessorWindow-countsWindow-repartition-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [OrderStreamProcessorWindow-countsWindow-repartition-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.075  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Notifying assignor about the new Assignment(partitions=[OrderStreamProcessorWindow-countsWindow-repartition-0], userDataSize=48)
2021-05-17 18:05:23.075  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.075  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Handle new assignment with:
	New active tasks: [1_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.077  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Successfully joined group with generation 3
2021-05-17 18:05:23.077  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Successfully joined group with generation 3
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Updating assignment with
	Assigned partitions:                       [OrderStreamProcessor2-orders-status-count-repartition-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [OrderStreamProcessor2-orders-status-count-repartition-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Notifying assignor about the new Assignment(partitions=[OrderStreamProcessor2-orders-status-count-repartition-0], userDataSize=48)
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Adding newly assigned partitions: OrderStreamProcessorWindow-countsWindow-repartition-0
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [1_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Updating assignment with
	Assigned partitions:                       [orders-window-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [orders-window-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Notifying assignor about the new Assignment(partitions=[orders-window-0], userDataSize=48)
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.078  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.083  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.083  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.083  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.083  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.085  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Found no committed offset for partition orders-0
2021-05-17 18:05:23.085  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Adding newly assigned partitions: orders-window-0
2021-05-17 18:05:23.085 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Received error code 1 - shutdown
2021-05-17 18:05:23.085  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Informed to shut down
2021-05-17 18:05:23.085  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Shutting down
2021-05-17 18:05:23.085  INFO 18012 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderConsumer-0, groupId=demo-alarm-event] Resetting offset for partition orders-0 to offset 0.
2021-05-17 18:05:23.085  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [0_0] Suspended created
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Adding newly assigned partitions: OrderStreamProcessor2-orders-status-count-repartition-0
2021-05-17 18:05:23.090 ERROR 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Received error code 1 - shutdown
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Informed to shut down
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.ProcessorStateManager        : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [1_0] State store countsWindow did not find checkpoint offset, hence would default to the starting offset at changelog OrderStreamProcessorWindow-countsWindow-changelog-0
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [1_0] Initialized
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Shutting down
2021-05-17 18:05:23.090  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] Suspended created
2021-05-17 18:05:23.093  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
2021-05-17 18:05:23.096  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
2021-05-17 18:05:23.096  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.RecordCollectorImpl  : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] Closing record collector clean
2021-05-17 18:05:23.097  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.RecordCollectorImpl  : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [0_0] Closing record collector clean
2021-05-17 18:05:23.097  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] Closed clean
2021-05-17 18:05:23.097  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [0_0] Closed clean
2021-05-17 18:05:23.098  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Resetting offset for partition orders-0 to offset 0.
2021-05-17 18:05:23.099  INFO 18012 --- [-StreamThread-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=OrderStreamProcessor2-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2021-05-17 18:05:23.099  INFO 18012 --- [-StreamThread-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=OrderStreamProcessorWindow-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2021-05-17 18:05:23.104  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.104  INFO 18012 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=NumberConsumer-0, groupId=demo-alarm-event] Resetting offset for partition numbers-0 to offset 0.
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.105  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.107  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
2021-05-17 18:05:23.107  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
2021-05-17 18:05:23.108  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Found no committed offset for partition orders-window-0
2021-05-17 18:05:23.108  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Found no committed offset for partition OrderStreamProcessor2-orders-status-count-repartition-0
2021-05-17 18:05:23.109  INFO 18012 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=ReturnConsumer-0, groupId=demo-alarm-event] Resetting offset for partition returns-0 to offset 0.
2021-05-17 18:05:23.116  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [0_0] Initialized
2021-05-17 18:05:23.122  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2021-05-17 18:05:23.122  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from REBALANCING to ERROR
2021-05-17 18:05:23.124 ERROR 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] All stream threads have died. The instance will be in error state and should be closed.
2021-05-17 18:05:23.124  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] Shutdown complete
2021-05-17 18:05:23.127  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
2021-05-17 18:05:23.128  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from REBALANCING to ERROR
2021-05-17 18:05:23.128 ERROR 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] All stream threads have died. The instance will be in error state and should be closed.
2021-05-17 18:05:23.128  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Shutdown complete
2021-05-17 18:05:23.130  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Found no committed offset for partition orders-0
2021-05-17 18:05:23.134  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [0_0] Restored and ready to run
2021-05-17 18:05:23.135  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.135  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.142  INFO 18012 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : demo-alarm-event: partitions assigned: [numbers-0]
2021-05-17 18:05:23.142  INFO 18012 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : demo-alarm-event: partitions assigned: [returns-0]
2021-05-17 18:05:23.142  INFO 18012 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : demo-alarm-event: partitions assigned: [orders-0]
2021-05-17 18:05:23.162  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Subscribed to partition(s): OrderStreamProcessorWindow-countsWindow-changelog-0
2021-05-17 18:05:23.163  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Seeking to EARLIEST offset of partition OrderStreamProcessorWindow-countsWindow-changelog-0
2021-05-17 18:05:23.176  INFO 18012 --- [ProcessorWindow] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Found no committed offset for partition OrderStreamProcessorWindow-countsWindow-repartition-0
2021-05-17 18:05:23.180  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:23.189  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-restore-consumer, groupId=null] Resetting offset for partition OrderStreamProcessorWindow-countsWindow-changelog-0 to offset 0.
2021-05-17 18:05:23.192  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.192  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.192  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.193  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.203  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.204  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.258  INFO 18012 --- [           main] .d.s.w.r.o.CachingOperationNameGenerator : Generating unique operation named: getOrdersUsingGET_1
2021-05-17 18:05:23.268  INFO 18012 --- [           main] .d.s.w.r.o.CachingOperationNameGenerator : Generating unique operation named: sendMessageToKafkaTopicUsingPOST_1
2021-05-17 18:05:23.283  INFO 18012 --- [           main] c.e.k.KafkaEventAlarmApplication         : Started KafkaEventAlarmApplication in 5.131 seconds (JVM running for 6.023)
2021-05-17 18:05:23.299  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.299  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StoreChangelogReader         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Finished restoring changelog OrderStreamProcessorWindow-countsWindow-changelog-0 to store countsWindow with a total number of 0 records
2021-05-17 18:05:23.299  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.299  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.299  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.307  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Found no committed offset for partition OrderStreamProcessorWindow-countsWindow-repartition-0
2021-05-17 18:05:23.308  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.309  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.312  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [1_0] Restored and ready to run
2021-05-17 18:05:23.312  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.312  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.317  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Resetting offset for partition OrderStreamProcessorWindow-countsWindow-repartition-0 to offset 0.
2021-05-17 18:05:23.402  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.402  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.402  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.402  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.410  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.504  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.504  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.504  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.504  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.512  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.513  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.529  INFO 18012 --- [   scheduling-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values:
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = true
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2021-05-17 18:05:23.529  WARN 18012 --- [   scheduling-1] o.a.k.clients.producer.ProducerConfig    : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2021-05-17 18:05:23.529  INFO 18012 --- [   scheduling-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.6.0
2021-05-17 18:05:23.529  INFO 18012 --- [   scheduling-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 62abe01bee039651
2021-05-17 18:05:23.529  INFO 18012 --- [   scheduling-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1621289123529
2021-05-17 18:05:23.556  INFO 18012 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:23.611  INFO 18012 --- [-StreamThread-1] o.a.k.s.s.i.RocksDBTimestampedStore      : Opening store counts in regular mode
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.ProcessorStateManager        : stream-thread [NumberStreamProcessor2-StreamThread-1] task [1_0] State store counts did not find checkpoint offset, hence would default to the starting offset at changelog NumberStreamProcessor2-counts-changelog-0
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [1_0] Initialized
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.617  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.618  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.621  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Found no committed offset for partition numbers-0
2021-05-17 18:05:23.621  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Restored and ready to run
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.625  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.628  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Subscribed to partition(s): NumberStreamProcessor2-counts-changelog-0
2021-05-17 18:05:23.629  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Seeking to EARLIEST offset of partition NumberStreamProcessor2-counts-changelog-0
2021-05-17 18:05:23.636  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:23.643  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Resetting offset for partition NumberStreamProcessor2-counts-changelog-0 to offset 0.
2021-05-17 18:05:23.657  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=bc40bc6c-8f62-4a51-bb5a-fef99589396f, product=0, orderTimestamp=2021-05-17T22:05:23.529170800Z, status=NEW)
2021-05-17 18:05:23.728  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.728  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.728  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.728  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.736  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 2
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       []
	Current owned partitions:                  []
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[], userDataSize=40)
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner.
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.737  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StoreChangelogReader         : stream-thread [NumberStreamProcessor2-StreamThread-1] Finished restoring changelog NumberStreamProcessor2-counts-changelog-0 to store counts with a total number of 0 records
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       [NumberStreamProcessor2-counts-repartition-0]
	Current owned partitions:                  [NumberStreamProcessor2-counts-repartition-0, numbers-0]
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     [numbers-0]

2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Revoke previously assigned partitions numbers-0
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to PARTITIONS_REVOKED
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Suspended running
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] partition revocation took 0 ms.
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0], userDataSize=48)
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [1_0]
	New standby tasks: []
	Existing active tasks: [0_0, 1_0]
	Existing standby tasks: []
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Subscribed to partition(s): NumberStreamProcessor2-counts-changelog-0
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.RecordCollectorImpl  : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Closing record collector clean
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Closed clean
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.752  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.830  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.831  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.831  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms.
2021-05-17 18:05:23.831  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] (Re-)joining group
2021-05-17 18:05:23.853  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([NumberStreamProcessor2-counts-repartition-0]) changelogOffsetTotalsByTask: ([1_0=0]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1], 2b4baf5a-ae10-437c-85f8-5087c470e060=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]} with no followup probing rebalance.
2021-05-17 18:05:23.853  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
2b4baf5a-ae10-437c-85f8-5087c470e060=[activeTasks: ([0_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1]
b0c21cec-8d6c-48f2-8619-45fa58925dc5=[activeTasks: ([1_0]) standbyTasks: ([]) prevActiveTasks: ([1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([NumberStreamProcessor2-counts-repartition-0]) changelogOffsetTotalsByTask: ([1_0=0]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 1].
2021-05-17 18:05:23.854  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:23.854  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Finished assignment for group at generation 3: {NumberStreamProcessor2-StreamThread-1-consumer-438924a5-16f8-4be1-bbbc-ab7e65f4f73a=Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0], userDataSize=48), NumberStreamProcessor2-StreamThread-1-consumer-e1fd483a-6582-4395-bdba-fdf1746f8cd3=Assignment(partitions=[numbers-0], userDataSize=48)}
2021-05-17 18:05:23.855  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Found no committed offset for partition NumberStreamProcessor2-counts-repartition-0
2021-05-17 18:05:23.857  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [1_0] Restored and ready to run
2021-05-17 18:05:23.857  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.857  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:23.859  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 3
2021-05-17 18:05:23.859  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Successfully joined group with generation 3
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       [numbers-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [numbers-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[numbers-0], userDataSize=48)
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Updating assignment with
	Assigned partitions:                       [NumberStreamProcessor2-counts-repartition-0]
	Current owned partitions:                  [NumberStreamProcessor2-counts-repartition-0]
	Added partitions (assigned - owned):       []
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Notifying assignor about the new Assignment(partitions=[NumberStreamProcessor2-counts-repartition-0], userDataSize=48)
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [NumberStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [NumberStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [1_0]
	New standby tasks: []
	Existing active tasks: [1_0]
	Existing standby tasks: []
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions:
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.860  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.861  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Adding newly assigned partitions: numbers-0
2021-05-17 18:05:23.861  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:23.861  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:23.863  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Found no committed offset for partition NumberStreamProcessor2-counts-repartition-0
2021-05-17 18:05:23.864  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Found no committed offset for partition numbers-0
2021-05-17 18:05:23.868  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Resetting offset for partition NumberStreamProcessor2-counts-repartition-0 to offset 0.
2021-05-17 18:05:23.874  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Resetting offset for partition numbers-0 to offset 0.
2021-05-17 18:05:23.938  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Initialized
2021-05-17 18:05:23.944  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=NumberStreamProcessor2-StreamThread-1-consumer, groupId=NumberStreamProcessor2] Found no committed offset for partition numbers-0
2021-05-17 18:05:23.945  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [NumberStreamProcessor2-StreamThread-1] task [0_0] Restored and ready to run
2021-05-17 18:05:23.945  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.945  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
    KafkaStreamNumberProcessor-Process Key=bc40bc6c-8f62-4a51-bb5a-fef99589396f  value=Order(orderId=bc40bc6c-8f62-4a51-bb5a-fef99589396f, product=0, orderTimestamp=2021-05-17T22:05:23.529170800Z, status=NEW)
2021-05-17 18:05:23.972  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [NumberStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:23.973  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [NumberStreamProcessor2] State transition from REBALANCING to RUNNING
    KafkaStreamNumberProcessor-Process Key=0f6013f0-2c3c-45be-89bd-2514a9627209  value=Order(orderId=0f6013f0-2c3c-45be-89bd-2514a9627209, product=1, orderTimestamp=2021-05-17T22:05:26.294090800Z, status=NEW)
2021-05-17 18:05:26.302  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=0f6013f0-2c3c-45be-89bd-2514a9627209, product=1, orderTimestamp=2021-05-17T22:05:26.294090800Z, status=NEW)
2021-05-17 18:05:29.311  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=58a78b95-1e9e-43a6-82fc-fdde96726c64, product=2, orderTimestamp=2021-05-17T22:05:29.304016100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=58a78b95-1e9e-43a6-82fc-fdde96726c64  value=Order(orderId=58a78b95-1e9e-43a6-82fc-fdde96726c64, product=2, orderTimestamp=2021-05-17T22:05:29.304016100Z, status=NEW)
2021-05-17 18:05:32.303  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=6ab8308d-8d2e-4f7a-84de-01f2e5c40c8b, product=3, orderTimestamp=2021-05-17T22:05:32.296513300Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=6ab8308d-8d2e-4f7a-84de-01f2e5c40c8b  value=Order(orderId=6ab8308d-8d2e-4f7a-84de-01f2e5c40c8b, product=3, orderTimestamp=2021-05-17T22:05:32.296513300Z, status=NEW)
2021-05-17 18:05:35.112  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Attempt to heartbeat failed since group is rebalancing
2021-05-17 18:05:35.112  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Attempt to heartbeat failed since group is rebalancing
2021-05-17 18:05:35.113  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] (Re-)joining group
2021-05-17 18:05:35.113  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] (Re-)joining group
2021-05-17 18:05:35.133  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {0fa30c47-d32d-481f-957a-43e2c0c7e4a3=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([OrderStreamProcessorWindow-countsWindow-repartition-0]) changelogOffsetTotalsByTask: ([1_0=-2]) taskLagTotals: ([1_0=-2]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2021-05-17 18:05:35.134  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Assigned tasks to clients as
0fa30c47-d32d-481f-957a-43e2c0c7e4a3=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([1_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([OrderStreamProcessorWindow-countsWindow-repartition-0]) changelogOffsetTotalsByTask: ([1_0=-2]) taskLagTotals: ([1_0=-2]) capacity: 1 assigned: 2].
2021-05-17 18:05:35.134  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:35.134  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Finished assignment for group at generation 4: {OrderStreamProcessorWindow-StreamThread-1-consumer-57d99ddf-fdc1-4331-b5e5-da0e70cf635e=Assignment(partitions=[OrderStreamProcessorWindow-countsWindow-repartition-0, orders-window-0], userDataSize=56)}
2021-05-17 18:05:35.137  INFO 18012 --- [-StreamThread-1] a.k.s.p.i.a.HighAvailabilityTaskAssignor : Decided on assignment: {676f7e50-93dc-4be5-ad75-34256c835121=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([0_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([orders-0]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2021-05-17 18:05:35.137  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Assigned tasks to clients as
676f7e50-93dc-4be5-ad75-34256c835121=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([0_0]) prevStandbyTasks: ([]) prevOwnedPartitionsByConsumerId: ([orders-0]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([1_0=0]) capacity: 1 assigned: 2].
2021-05-17 18:05:35.138  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2021-05-17 18:05:35.138  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Finished assignment for group at generation 4: {OrderStreamProcessor2-StreamThread-1-consumer-bf6909b2-f484-4542-afdf-7465f8e3477d=Assignment(partitions=[OrderStreamProcessor2-orders-status-count-repartition-0, orders-0], userDataSize=56)}
2021-05-17 18:05:35.139  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Successfully joined group with generation 4
2021-05-17 18:05:35.139  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Updating assignment with
	Assigned partitions:                       [OrderStreamProcessorWindow-countsWindow-repartition-0, orders-window-0]
	Current owned partitions:                  [OrderStreamProcessorWindow-countsWindow-repartition-0]
	Added partitions (assigned - owned):       [orders-window-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:35.139  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Notifying assignor about the new Assignment(partitions=[orders-window-0, OrderStreamProcessorWindow-countsWindow-repartition-0], userDataSize=56)
2021-05-17 18:05:35.139  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessorWindow-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:35.139  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessorWindow-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0, 1_0]
	New standby tasks: []
	Existing active tasks: [1_0]
	Existing standby tasks: []
2021-05-17 18:05:35.141  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Adding newly assigned partitions: orders-window-0
2021-05-17 18:05:35.141  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:35.141  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from RUNNING to REBALANCING
2021-05-17 18:05:35.142  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Successfully joined group with generation 4
2021-05-17 18:05:35.143  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Updating assignment with
	Assigned partitions:                       [OrderStreamProcessor2-orders-status-count-repartition-0, orders-0]
	Current owned partitions:                  [orders-0]
	Added partitions (assigned - owned):       [OrderStreamProcessor2-orders-status-count-repartition-0]
	Revoked partitions (owned - assigned):     []

2021-05-17 18:05:35.143  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Notifying assignor about the new Assignment(partitions=[OrderStreamProcessor2-orders-status-count-repartition-0, orders-0], userDataSize=56)
2021-05-17 18:05:35.143  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StreamsPartitionAssignor     : stream-thread [OrderStreamProcessor2-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2021-05-17 18:05:35.143  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.TaskManager  : stream-thread [OrderStreamProcessor2-StreamThread-1] Handle new assignment with:
	New active tasks: [0_0, 1_0]
	New standby tasks: []
	Existing active tasks: [0_0]
	Existing standby tasks: []
2021-05-17 18:05:35.144  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Found no committed offset for partition orders-window-0
2021-05-17 18:05:35.145  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Adding newly assigned partitions: OrderStreamProcessor2-orders-status-count-repartition-0
2021-05-17 18:05:35.145  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED
2021-05-17 18:05:35.145  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from RUNNING to REBALANCING
2021-05-17 18:05:35.148  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Found no committed offset for partition OrderStreamProcessor2-orders-status-count-repartition-0
2021-05-17 18:05:35.206  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [0_0] Initialized
2021-05-17 18:05:35.209  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Found no committed offset for partition orders-window-0
2021-05-17 18:05:35.209  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessorWindow-StreamThread-1] task [0_0] Restored and ready to run
2021-05-17 18:05:35.209  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessorWindow-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:35.210  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessorWindow] State transition from REBALANCING to RUNNING
2021-05-17 18:05:35.269  INFO 18012 --- [-StreamThread-1] o.a.k.s.s.i.RocksDBTimestampedStore      : Opening store orders-status-count in regular mode
2021-05-17 18:05:35.269  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.ProcessorStateManager        : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] State store orders-status-count did not find checkpoint offset, hence would default to the starting offset at changelog OrderStreamProcessor2-orders-status-count-changelog-0
2021-05-17 18:05:35.269  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] Initialized
2021-05-17 18:05:35.288  INFO 18012 --- [-StreamThread-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Subscribed to partition(s): OrderStreamProcessor2-orders-status-count-changelog-0
2021-05-17 18:05:35.288  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Seeking to EARLIEST offset of partition OrderStreamProcessor2-orders-status-count-changelog-0
2021-05-17 18:05:35.297  INFO 18012 --- [-StreamThread-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Cluster ID: gQd0SZFdTcm8bQA98hSDxg
2021-05-17 18:05:35.309  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=4a29b118-be11-4870-8160-dfad1d4d2dde, product=4, orderTimestamp=2021-05-17T22:05:35.297885800Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=4a29b118-be11-4870-8160-dfad1d4d2dde  value=Order(orderId=4a29b118-be11-4870-8160-dfad1d4d2dde, product=4, orderTimestamp=2021-05-17T22:05:35.297885800Z, status=NEW)
2021-05-17 18:05:35.318  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-restore-consumer, groupId=null] Resetting offset for partition OrderStreamProcessor2-orders-status-count-changelog-0 to offset 0.
2021-05-17 18:05:35.421  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.i.StoreChangelogReader         : stream-thread [OrderStreamProcessor2-StreamThread-1] Finished restoring changelog OrderStreamProcessor2-orders-status-count-changelog-0 to store orders-status-count with a total number of 0 records
2021-05-17 18:05:35.421  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Resetting offset for partition OrderStreamProcessor2-orders-status-count-repartition-0 to offset 0.
2021-05-17 18:05:35.423  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=OrderStreamProcessor2-StreamThread-1-consumer, groupId=OrderStreamProcessor2] Found no committed offset for partition OrderStreamProcessor2-orders-status-count-repartition-0
2021-05-17 18:05:35.425  INFO 18012 --- [-StreamThread-1] o.a.k.s.processor.internals.StreamTask   : stream-thread [OrderStreamProcessor2-StreamThread-1] task [1_0] Restored and ready to run
2021-05-17 18:05:35.425  INFO 18012 --- [-StreamThread-1] o.a.k.s.p.internals.StreamThread         : stream-thread [OrderStreamProcessor2-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2021-05-17 18:05:35.425  INFO 18012 --- [-StreamThread-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=OrderStreamProcessorWindow-StreamThread-1-consumer, groupId=OrderStreamProcessorWindow] Resetting offset for partition orders-window-0 to offset 0.
2021-05-17 18:05:35.425  INFO 18012 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [OrderStreamProcessor2] State transition from REBALANCING to RUNNING
2021-05-17 18:05:38.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=b0716d66-f935-4a6e-8116-657d8a0482b0, product=5, orderTimestamp=2021-05-17T22:05:38.298916100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=b0716d66-f935-4a6e-8116-657d8a0482b0  value=Order(orderId=b0716d66-f935-4a6e-8116-657d8a0482b0, product=5, orderTimestamp=2021-05-17T22:05:38.298916100Z, status=NEW)
2021-05-17 18:05:41.296  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=2dac7e9f-fbff-4d37-925c-72e766b6bddc, product=6, orderTimestamp=2021-05-17T22:05:41.290756100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=2dac7e9f-fbff-4d37-925c-72e766b6bddc  value=Order(orderId=2dac7e9f-fbff-4d37-925c-72e766b6bddc, product=6, orderTimestamp=2021-05-17T22:05:41.290756100Z, status=NEW)
2021-05-17 18:05:44.312  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=eba21544-0694-43f6-9a12-a55152dbde75, product=7, orderTimestamp=2021-05-17T22:05:44.305223Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=eba21544-0694-43f6-9a12-a55152dbde75  value=Order(orderId=eba21544-0694-43f6-9a12-a55152dbde75, product=7, orderTimestamp=2021-05-17T22:05:44.305223Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=9a08a6b3-6c98-404a-a427-f17b29ce1c35  value=Order(orderId=9a08a6b3-6c98-404a-a427-f17b29ce1c35, product=8, orderTimestamp=2021-05-17T22:05:47.303953500Z, status=NEW)
2021-05-17 18:05:47.310  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=9a08a6b3-6c98-404a-a427-f17b29ce1c35, product=8, orderTimestamp=2021-05-17T22:05:47.303953500Z, status=NEW)
2021-05-17 18:05:50.301  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=87dc861f-a24f-4465-b69c-88963bb664bf, product=9, orderTimestamp=2021-05-17T22:05:50.296800100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=87dc861f-a24f-4465-b69c-88963bb664bf  value=Order(orderId=87dc861f-a24f-4465-b69c-88963bb664bf, product=9, orderTimestamp=2021-05-17T22:05:50.296800100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=34bd560e-11bc-4a31-9cc3-036b2ab23b6a  value=Order(orderId=34bd560e-11bc-4a31-9cc3-036b2ab23b6a, product=10, orderTimestamp=2021-05-17T22:05:53.298602100Z, status=NEW)
2021-05-17 18:05:53.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=34bd560e-11bc-4a31-9cc3-036b2ab23b6a, product=10, orderTimestamp=2021-05-17T22:05:53.298602100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=f60e1612-455e-451c-a4ac-d95782d9c954  value=Order(orderId=f60e1612-455e-451c-a4ac-d95782d9c954, product=11, orderTimestamp=2021-05-17T22:05:56.300302Z, status=NEW)
2021-05-17 18:05:56.306  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=f60e1612-455e-451c-a4ac-d95782d9c954, product=11, orderTimestamp=2021-05-17T22:05:56.300302Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=f1c895bb-2a09-44da-8a79-f8a329976336  value=Order(orderId=f1c895bb-2a09-44da-8a79-f8a329976336, product=12, orderTimestamp=2021-05-17T22:05:59.295599800Z, status=NEW)
2021-05-17 18:05:59.301  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=f1c895bb-2a09-44da-8a79-f8a329976336, product=12, orderTimestamp=2021-05-17T22:05:59.295599800Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=5c1a644f-e74a-4312-8481-46b33f65016a  value=Order(orderId=5c1a644f-e74a-4312-8481-46b33f65016a, product=13, orderTimestamp=2021-05-17T22:06:02.304048500Z, status=NEW)
2021-05-17 18:06:02.309  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=5c1a644f-e74a-4312-8481-46b33f65016a, product=13, orderTimestamp=2021-05-17T22:06:02.304048500Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=4de76997-766a-43f4-9af0-db5513e23ebd  value=Order(orderId=4de76997-766a-43f4-9af0-db5513e23ebd, product=14, orderTimestamp=2021-05-17T22:06:05.291585Z, status=NEW)
2021-05-17 18:06:05.297  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=4de76997-766a-43f4-9af0-db5513e23ebd, product=14, orderTimestamp=2021-05-17T22:06:05.291585Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=f8918b0f-869c-4f07-9276-e89ea141f271  value=Order(orderId=f8918b0f-869c-4f07-9276-e89ea141f271, product=15, orderTimestamp=2021-05-17T22:06:08.292380500Z, status=NEW)
2021-05-17 18:06:08.298  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=f8918b0f-869c-4f07-9276-e89ea141f271, product=15, orderTimestamp=2021-05-17T22:06:08.292380500Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=37e99012-2764-4e3f-bcf3-65d843ce7dd0  value=Order(orderId=37e99012-2764-4e3f-bcf3-65d843ce7dd0, product=16, orderTimestamp=2021-05-17T22:06:11.292038700Z, status=NEW)
2021-05-17 18:06:11.297  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=37e99012-2764-4e3f-bcf3-65d843ce7dd0, product=16, orderTimestamp=2021-05-17T22:06:11.292038700Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=c28d9d88-9c01-4a60-a612-aa359dd02d04  value=Order(orderId=c28d9d88-9c01-4a60-a612-aa359dd02d04, product=17, orderTimestamp=2021-05-17T22:06:14.295496900Z, status=NEW)
2021-05-17 18:06:14.300  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=c28d9d88-9c01-4a60-a612-aa359dd02d04, product=17, orderTimestamp=2021-05-17T22:06:14.295496900Z, status=NEW)
2021-05-17 18:06:17.306  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=1a53d9fc-b104-40c7-81c5-70146fe934ee, product=18, orderTimestamp=2021-05-17T22:06:17.300415200Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=1a53d9fc-b104-40c7-81c5-70146fe934ee  value=Order(orderId=1a53d9fc-b104-40c7-81c5-70146fe934ee, product=18, orderTimestamp=2021-05-17T22:06:17.300415200Z, status=NEW)
2021-05-17 18:06:20.309  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=e890f758-9493-446c-9fb7-0b0c4ca1fd4f, product=19, orderTimestamp=2021-05-17T22:06:20.305361900Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=e890f758-9493-446c-9fb7-0b0c4ca1fd4f  value=Order(orderId=e890f758-9493-446c-9fb7-0b0c4ca1fd4f, product=19, orderTimestamp=2021-05-17T22:06:20.305361900Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=e7fe1ede-2417-40c8-9716-8d1ba6f1ea4f  value=Order(orderId=e7fe1ede-2417-40c8-9716-8d1ba6f1ea4f, product=20, orderTimestamp=2021-05-17T22:06:23.305321600Z, status=NEW)
2021-05-17 18:06:23.310  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=e7fe1ede-2417-40c8-9716-8d1ba6f1ea4f, product=20, orderTimestamp=2021-05-17T22:06:23.305321600Z, status=NEW)
2021-05-17 18:06:23.352  INFO 18012 --- [nio-8282-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2021-05-17 18:06:23.352  INFO 18012 --- [nio-8282-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2021-05-17 18:06:23.352  INFO 18012 --- [nio-8282-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 0 ms
    KafkaStreamNumberProcessor-Process Key=7bc79615-b519-4d0d-9a9a-52c804becccb  value=Order(orderId=7bc79615-b519-4d0d-9a9a-52c804becccb, product=21, orderTimestamp=2021-05-17T22:06:26.302980Z, status=NEW)
2021-05-17 18:06:26.307  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=7bc79615-b519-4d0d-9a9a-52c804becccb, product=21, orderTimestamp=2021-05-17T22:06:26.302980Z, status=NEW)
2021-05-17 18:06:29.295  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=b6c68ae2-cc84-478c-a96f-b64d991dce35, product=22, orderTimestamp=2021-05-17T22:06:29.290860Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=b6c68ae2-cc84-478c-a96f-b64d991dce35  value=Order(orderId=b6c68ae2-cc84-478c-a96f-b64d991dce35, product=22, orderTimestamp=2021-05-17T22:06:29.290860Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=179360c0-9275-4902-b219-6efcd4c8fc64  value=Order(orderId=179360c0-9275-4902-b219-6efcd4c8fc64, product=23, orderTimestamp=2021-05-17T22:06:32.290680200Z, status=NEW)
2021-05-17 18:06:32.295  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=179360c0-9275-4902-b219-6efcd4c8fc64, product=23, orderTimestamp=2021-05-17T22:06:32.290680200Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=03f76f9a-e9dc-467d-bc6f-084744213e7f  value=Order(orderId=03f76f9a-e9dc-467d-bc6f-084744213e7f, product=24, orderTimestamp=2021-05-17T22:06:35.298798300Z, status=NEW)
2021-05-17 18:06:35.303  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=03f76f9a-e9dc-467d-bc6f-084744213e7f, product=24, orderTimestamp=2021-05-17T22:06:35.298798300Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=2ea6f3f8-a240-4b5f-8352-7a09adc68b74  value=Order(orderId=2ea6f3f8-a240-4b5f-8352-7a09adc68b74, product=25, orderTimestamp=2021-05-17T22:06:38.300558200Z, status=NEW)
2021-05-17 18:06:38.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=2ea6f3f8-a240-4b5f-8352-7a09adc68b74, product=25, orderTimestamp=2021-05-17T22:06:38.300558200Z, status=NEW)
2021-05-17 18:06:41.309  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=33875891-9e0e-4f3d-901f-44915bb2a2c3, product=26, orderTimestamp=2021-05-17T22:06:41.303902200Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=33875891-9e0e-4f3d-901f-44915bb2a2c3  value=Order(orderId=33875891-9e0e-4f3d-901f-44915bb2a2c3, product=26, orderTimestamp=2021-05-17T22:06:41.303902200Z, status=NEW)
2021-05-17 18:06:44.296  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=cbd09520-04b6-4aaa-bbb1-8ecbfdeed9fe, product=27, orderTimestamp=2021-05-17T22:06:44.291514400Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=cbd09520-04b6-4aaa-bbb1-8ecbfdeed9fe  value=Order(orderId=cbd09520-04b6-4aaa-bbb1-8ecbfdeed9fe, product=27, orderTimestamp=2021-05-17T22:06:44.291514400Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=5e4bffc7-2126-43a8-8d3b-a170016af2f6  value=Order(orderId=5e4bffc7-2126-43a8-8d3b-a170016af2f6, product=28, orderTimestamp=2021-05-17T22:06:47.292159700Z, status=NEW)
2021-05-17 18:06:47.297  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=5e4bffc7-2126-43a8-8d3b-a170016af2f6, product=28, orderTimestamp=2021-05-17T22:06:47.292159700Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=38df63d8-b2a1-4f80-8a1e-eb7c3c1966bb  value=Order(orderId=38df63d8-b2a1-4f80-8a1e-eb7c3c1966bb, product=29, orderTimestamp=2021-05-17T22:06:50.297941900Z, status=NEW)
2021-05-17 18:06:50.303  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=38df63d8-b2a1-4f80-8a1e-eb7c3c1966bb, product=29, orderTimestamp=2021-05-17T22:06:50.297941900Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=ee313b43-3960-4d6e-97e3-db937b1bc1de  value=Order(orderId=ee313b43-3960-4d6e-97e3-db937b1bc1de, product=30, orderTimestamp=2021-05-17T22:06:53.302246300Z, status=NEW)
2021-05-17 18:06:53.306  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=ee313b43-3960-4d6e-97e3-db937b1bc1de, product=30, orderTimestamp=2021-05-17T22:06:53.302246300Z, status=NEW)
2021-05-17 18:06:56.296  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=1ac06fb4-573f-402b-8529-1288e2437038, product=31, orderTimestamp=2021-05-17T22:06:56.290255100Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=1ac06fb4-573f-402b-8529-1288e2437038  value=Order(orderId=1ac06fb4-573f-402b-8529-1288e2437038, product=31, orderTimestamp=2021-05-17T22:06:56.290255100Z, status=NEW)
2021-05-17 18:06:59.314  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=2f466ff1-7b69-44ff-b777-907ddb26acad, product=32, orderTimestamp=2021-05-17T22:06:59.309834300Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=2f466ff1-7b69-44ff-b777-907ddb26acad  value=Order(orderId=2f466ff1-7b69-44ff-b777-907ddb26acad, product=32, orderTimestamp=2021-05-17T22:06:59.309834300Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=c803d357-8a8c-4b3b-897c-6a25ad452f73  value=Order(orderId=c803d357-8a8c-4b3b-897c-6a25ad452f73, product=33, orderTimestamp=2021-05-17T22:07:02.299660700Z, status=NEW)
2021-05-17 18:07:02.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=c803d357-8a8c-4b3b-897c-6a25ad452f73, product=33, orderTimestamp=2021-05-17T22:07:02.299660700Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=584eb1af-8359-42da-8587-9247decfefbe  value=Order(orderId=584eb1af-8359-42da-8587-9247decfefbe, product=34, orderTimestamp=2021-05-17T22:07:05.299710300Z, status=NEW)
2021-05-17 18:07:05.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=584eb1af-8359-42da-8587-9247decfefbe, product=34, orderTimestamp=2021-05-17T22:07:05.299710300Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=f0d73375-ee98-462f-a4bd-d3da59ddc0e6  value=Order(orderId=f0d73375-ee98-462f-a4bd-d3da59ddc0e6, product=35, orderTimestamp=2021-05-17T22:07:08.298645400Z, status=NEW)
2021-05-17 18:07:08.307  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=f0d73375-ee98-462f-a4bd-d3da59ddc0e6, product=35, orderTimestamp=2021-05-17T22:07:08.298645400Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=44276861-efbb-41bf-b5f2-f0f23245ad17  value=Order(orderId=44276861-efbb-41bf-b5f2-f0f23245ad17, product=36, orderTimestamp=2021-05-17T22:07:11.299610Z, status=NEW)
2021-05-17 18:07:11.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=44276861-efbb-41bf-b5f2-f0f23245ad17, product=36, orderTimestamp=2021-05-17T22:07:11.299610Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=edf21df1-c03e-4081-993b-99f929bd4d19  value=Order(orderId=edf21df1-c03e-4081-993b-99f929bd4d19, product=37, orderTimestamp=2021-05-17T22:07:14.299909900Z, status=NEW)
2021-05-17 18:07:14.305  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=edf21df1-c03e-4081-993b-99f929bd4d19, product=37, orderTimestamp=2021-05-17T22:07:14.299909900Z, status=NEW)
    KafkaStreamNumberProcessor-Process Key=48146722-1043-4412-a4a3-b2de72212194  value=Order(orderId=48146722-1043-4412-a4a3-b2de72212194, product=38, orderTimestamp=2021-05-17T22:07:17.309697500Z, status=NEW)
2021-05-17 18:07:17.314  INFO 18012 --- [ntainer#1-0-C-1] c.e.k.consumer.OrderNumberConsumer       : Order consumed (from Number Producer)-> Order(orderId=48146722-1043-4412-a4a3-b2de72212194, product=38, orderTimestamp=2021-05-17T22:07:17.309697500Z, status=NEW)